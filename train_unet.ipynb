{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da606827",
   "metadata": {},
   "source": [
    "Этот ноутбук настроен на обучение нейронной сети U-net в Google Colab.\n",
    "\n",
    "Предварительно надо поместить `segments.zip` по пути `/binarization/segments.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3692c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T11:38:00.319094Z",
     "start_time": "2022-06-26T11:37:56.795510Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install keras_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7add305a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T11:38:00.351821Z",
     "start_time": "2022-06-26T11:38:00.343627Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ed2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!cp /content/drive/MyDrive/binarization/segments.zip segments.zip\n",
    "!unzip segments.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2384a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T11:38:33.732765Z",
     "start_time": "2022-06-26T11:38:33.708631Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "original_paths = glob.glob(\"segments/original/*.bmp\")\n",
    "gt_paths = list(map(lambda x: x.replace(\"original\", \"gt\"), original_paths))\n",
    "\n",
    "print(len(original_paths), len(gt_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafcc871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T11:38:35.434208Z",
     "start_time": "2022-06-26T11:38:35.424332Z"
    }
   },
   "outputs": [],
   "source": [
    "first_count = 5\n",
    "for original_path, gt_path in zip(original_paths[:first_count], gt_paths[:first_count]):\n",
    "    print(original_path, gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e9dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T11:38:47.380193Z",
     "start_time": "2022-06-26T11:38:46.155044Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(original_paths, gt_paths, test_size=0.1, random_state=0)\n",
    "\n",
    "print(\"x_train: \", len(x_train))\n",
    "print(\"y_train: \", len(y_train))\n",
    "print(\"x_val: \", len(x_val))\n",
    "print(\"y_val: \", len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1572ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T11:38:51.057505Z",
     "start_time": "2022-06-26T11:38:51.045024Z"
    }
   },
   "outputs": [],
   "source": [
    "# imcollect.py\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "\n",
    "class PairsGenerator(Sequence):\n",
    "    \"\"\"Вспомогательный класс для итерации по изображениям. Подходит для обучения моделей Keras.\n",
    "    Нужен для того, чтобы не загружать весь датасет в память\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, original_img_paths, gt_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.original_paths = original_img_paths\n",
    "        self.gt_paths = gt_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Количество батчей\"\"\"\n",
    "        return len(self.original_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Возвращает батч (пару наборов изображений) по индексу\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_original_img_paths = self.original_paths[i: i + self.batch_size]\n",
    "        batch_gt_img_paths = self.gt_paths[i: i + self.batch_size]\n",
    "        original = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_original_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size)\n",
    "            original[j] = np.array(img) / 255\n",
    "        gt = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_gt_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            gt[j] = np.expand_dims(img, 2) / 255\n",
    "        return original, gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf17c7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T11:40:42.317111Z",
     "start_time": "2022-06-26T11:40:42.295683Z"
    }
   },
   "outputs": [],
   "source": [
    "segment_size = 256\n",
    "batch_size = 32\n",
    "pairgen = PairsGenerator(batch_size, segment_size, x_train, y_train)\n",
    "val_pairgen = PairsGenerator(batch_size, segment_size, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95675e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T11:38:56.153792Z",
     "start_time": "2022-06-26T11:38:55.821354Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = pairgen[0]\n",
    "print(x.shape, y.shape)\n",
    "print(x.dtype, y.dtype)\n",
    "print(x[0].max(), y[0].max())\n",
    "print(len(pairgen), len(val_pairgen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66afbf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.models import vanilla_unet, custom_unet\n",
    "\n",
    "model = custom_unet(input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model_filename = 'segm_model_v3.h5'\n",
    "callback_checkpoint = ModelCheckpoint(\n",
    "    model_filename,\n",
    "    verbose=1,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fa150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(), \n",
    "    #optimizer=SGD(lr=0.01, momentum=0.99),\n",
    "    loss='binary_crossentropy',\n",
    "    #loss=jaccard_distance,\n",
    "    metrics=[iou, iou_thresholded]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    pairgen,\n",
    "    steps_per_epoch=len(pairgen),\n",
    "    validation_data=val_pairgen,\n",
    "    validation_steps=len(val_pairgen),\n",
    "    epochs=10,\n",
    "    callbacks=[callback_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce2dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423fc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50854f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['iou'])\n",
    "plt.plot(history.history['val_iou'])\n",
    "plt.title('model iou')\n",
    "plt.ylabel('iou')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['iou_thresholded'])\n",
    "plt.plot(history.history['val_iou_thresholded'])\n",
    "plt.title('model iou thresholded')\n",
    "plt.ylabel('iou thresholded')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d019549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "model.save(f'/content/drive/MyDrive/binarization/models/model.{int(time.time())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d4f37",
   "metadata": {},
   "source": [
    "Далее модель применяется к одному из изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc03332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели. В Google Colab можно не запускать\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "\n",
    "model_path = f\"models/model.1655852129\"\n",
    "model = tf.keras.models.load_model(model_path,\n",
    "                                   custom_objects=dict(iou_thresholded=iou_thresholded, iou=iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56826b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "path = '/content/drive/MyDrive/binarization/images/original/2image.png'\n",
    "\n",
    "test_image = cv.imread(path)\n",
    "test_image = test_image[...,::-1] / 255\n",
    "\n",
    "plt.imshow(test_image)\n",
    "print(test_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd89efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imsplit.py\n",
    "\n",
    "def _range_borders(start, finish, distance, step=None, full_cover=True):\n",
    "    if finish - start < distance:\n",
    "        return []\n",
    "    if step is None:\n",
    "        step = distance\n",
    "    pairs = []\n",
    "    for start_border in range(start, finish, step):\n",
    "        finish_border = start_border + distance\n",
    "        if finish_border > finish:\n",
    "            if full_cover:\n",
    "                pairs.append((finish - distance, finish))\n",
    "            return pairs\n",
    "        pairs.append((finish - distance, finish))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def replace_segments(crops, new_segments):\n",
    "    return [(segment, borders) for segment, (_, borders) in zip(new_segments, crops)]\n",
    "\n",
    "\n",
    "def imsplit(image, size, step=None, full_cover=True):\n",
    "    \"\"\"Метод для разделения изображения на квадратные сегменты\n",
    "\n",
    "    :param image: изображение\n",
    "    :param size: размер стороны сегмента в пикселях\n",
    "    :param step: смещение сегмента. Нужно, если требуется перекрытие сегментов. Если None, сегменты\n",
    "      не будут перекрываться (кроме последних крайних, что определяется параметром full_cover)\n",
    "    :param full_cover: нужно ли добавлять крайние сегменты, если при этом будет перекрытие с соседним\n",
    "      Например, при размере изображения 100 x 100 и размере сегмента 30 x 30 либо будет перекрытие\n",
    "      сегментов, либо крайние правые и нижние сегменты будут проигнорированы (full_cover=False)\n",
    "    :return: массив пар (сегмент, границы). Границы в формате PIL: (left, top, right, bottom)\n",
    "    \"\"\"\n",
    "    image = np.asarray(image)\n",
    "    if step is None:\n",
    "        step = size\n",
    "    crops = []\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    for top, bottom in _range_borders(0, h, size, step, full_cover=full_cover):\n",
    "        for left, right in _range_borders(0, w, size, step, full_cover=full_cover):\n",
    "            crops.append((image[top:bottom, left:right], (left, top, right, bottom)))\n",
    "    return crops\n",
    "\n",
    "\n",
    "def get_shape(crops):\n",
    "    assert len(crops) > 0, 'пустой массив сегментов'\n",
    "    max_right = 0\n",
    "    max_bottom = 0\n",
    "    segment_shape = None\n",
    "    for segment, (_, _, right, bottom) in crops:\n",
    "        if segment_shape is None:\n",
    "            segment_shape = segment.shape\n",
    "        assert segment.shape == segment_shape, 'все сегменты должны иметь одинаковый размер'\n",
    "        if max_right < right:\n",
    "            max_right = right\n",
    "        if max_bottom < bottom:\n",
    "            max_bottom = bottom\n",
    "    if len(segment_shape) == 2:\n",
    "        shape = max_bottom, max_right\n",
    "    elif segment_shape[2] == 1:\n",
    "        shape = max_bottom, max_right, 1\n",
    "    elif segment_shape[2] == 3:\n",
    "        shape = max_bottom, max_right, 3\n",
    "    else:\n",
    "        raise Exception('неправильный атрибут shape у сегментов', segment_shape)\n",
    "    return shape\n",
    "\n",
    "\n",
    "def imjoin_max(crops):\n",
    "    shape = get_shape(crops)\n",
    "    max_image = np.zeros(shape, dtype=np.float64)\n",
    "    for segment, (left, top, right, bottom) in crops:\n",
    "        max_image[top:bottom, left:right] = np.maximum(max_image[top:bottom, left:right], segment)\n",
    "    return max_image\n",
    "\n",
    "\n",
    "def imjoin_min(crops):\n",
    "    shape = get_shape(crops)\n",
    "    min_image = np.zeros(shape, dtype=np.float64)\n",
    "    for segment, (left, top, right, bottom) in crops:\n",
    "        min_image[top:bottom, left:right] = np.minimum(min_image[top:bottom, left:right], segment)\n",
    "    return min_image\n",
    "\n",
    "\n",
    "def imjoin_average(crops):\n",
    "    shape = get_shape(crops)\n",
    "    sum_image = np.zeros(shape, dtype=np.float64)\n",
    "    count_image = np.zeros(shape, dtype=np.float64)\n",
    "    for segment, (left, top, right, bottom) in crops:\n",
    "        sum_image[top:bottom, left:right] += segment\n",
    "        count_image[top:bottom, left:right] += 1\n",
    "    return sum_image / count_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = imsplit(test_image, 256, 64)\n",
    "\n",
    "len(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bfa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = np.array([segment for segment, _ in crops])\n",
    "\n",
    "batch.shape, batch.dtype, batch.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_batch = model.predict(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_crops = replace_segments(crops=crops, new_segments=result_batch)\n",
    "result_image = imjoin_average(result_crops)\n",
    "\n",
    "plt.imshow(np.squeeze(result_image), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "path = 'image.png'\n",
    "im = Image.fromarray(np.squeeze((result_image * 255).astype(np.uint8))).save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c232022f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
